# ‚úÖ –°–∫—Ä–∏–ø—Ç –∑ –ø–æ–≤–Ω–∏–º –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è–º –≤—Å—ñ—Ö HOG-—Ñ—ñ—á —É –ø–∞–º º—è—Ç—å (–¥–ª—è 15 –∫–ª–∞—Å—ñ–≤)
# –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º: –ø–µ—Ä–µ–∫–æ–Ω–∞–π—Å—è, —â–æ —î GPU —ñ –≤–∏—Å—Ç–∞—á–∞—î RAM (~20‚Äì30 –ì–ë)
# –î–æ–¥–∞—Ç–∫–æ–≤–æ: –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ Google Cloud Storage (GCS)
# –¢–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –Ω–∞–π–∫—Ä–∞—â–æ—ó –º–æ–¥–µ–ª—ñ –Ω–∞–∑–∞–¥ —É GCS

import os, pickle, time, zipfile, re
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
from PIL import Image
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
import psutil
import GPUtil

# GCS support
from google.colab import auth
from google.cloud import storage

# üîß –ü–∞—Ä–∞–º–µ—Ç—Ä–∏
BATCH_SIZE = 256
NUM_EPOCHS = 20
VALIDATION_SPLIT = 0.15
HOG_DIR = "hog_features"
IMG_ZIP = "spectrograms_bin.zip"
IMG_DIR = "spectrograms_bin"
GCS_BUCKET = "mfedechko-datasets"
MODEL_NAME = "best_model.pth"

CLASS_NAMES = [
    "LFM", "4FSK", "Costas", "2PSK", "Barker", "Huffman",
    "Frank", "P1", "P2", "P3", "P4", "T1", "T2", "T3", "T4"
]

# üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è —Ç–∞ GCS –∫–ª—ñ—î–Ω—Ç
auth.authenticate_user()
client = storage.Client()
bucket = client.bucket(GCS_BUCKET)

# üì¶ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å
if not os.path.exists(IMG_ZIP):
    print("‚¨áÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è spectrograms_bin.zip –∑ GCS...")
    bucket.blob(IMG_ZIP).download_to_filename(IMG_ZIP)

if not os.path.exists(IMG_DIR):
    print("üì¶ –†–æ–∑–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö—ñ–≤—É...")
    with zipfile.ZipFile(IMG_ZIP, 'r') as zip_ref:
        zip_ref.extractall(IMG_DIR)

# üì¶ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è HOG-—Ñ—ñ—á
if not os.path.exists(HOG_DIR):
    os.makedirs(HOG_DIR)
    print("‚¨áÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è HOG-—Ñ–∞–π–ª—ñ–≤ –∑ GCS...")
    for cls in CLASS_NAMES:
        blob_name = f"hog_features/{cls}.pkl"
        local_path = os.path.join(HOG_DIR, f"{cls}.pkl")
        if not os.path.exists(local_path):
            blob = bucket.blob(blob_name)
            blob.download_to_filename(local_path)
            print(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {cls}.pkl")


# üì¶ Dataset ‚Äî –∑ –ø–æ–≤–Ω–∏–º –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è–º –≤—Å—ñ—Ö HOG-—Ñ—ñ—á —É –ø–∞–º º—è—Ç—å
class FullHOGDataset(Dataset):
    def __init__(self, image_root, hog_dir, transform=None):
        self.transform = transform
        self.encoder = LabelEncoder()
        self.encoder.fit(CLASS_NAMES)

        self.data = []

        for cls in CLASS_NAMES:
            hog_file = os.path.join(hog_dir, f"{cls}.pkl")
            if not os.path.exists(hog_file):
                print(f"[!] HOG-—Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {hog_file}")
                continue
            with open(hog_file, "rb") as f:
                hog_data = pickle.load(f)

            for feat, fname, label in zip(hog_data["features"], hog_data["filenames"], hog_data["labels"]):
                match = re.search(r"_SNR(-?\d+)_", fname)
                if match and int(match.group(1)) >= -6:
                    image_path = os.path.join(image_root, cls, fname)
                    if os.path.exists(image_path):
                        self.data.append((image_path, torch.tensor(feat, dtype=torch.float32), label))

        print(f"üì¶ Dataset size: {len(self.data)}")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        image_path, hog_feat, label_str = self.data[idx]
        image = Image.open(image_path).convert("L")
        image = self.transform(image) if self.transform else torch.tensor(np.array(image) / 255.0).unsqueeze(0).float()
        label = self.encoder.transform([label_str])[0]
        return image, hog_feat, label


# üß† –ú–æ–¥–µ–ª—å
class DualChannelNet(nn.Module):
    def __init__(self, num_classes, hog_input_size):
        super().__init__()
        self.hog_fc = nn.Sequential(
            nn.Linear(hog_input_size, 512), nn.ReLU(), nn.Dropout(0.3),
            nn.Linear(512, 256)
        )
        self.img_cnn = nn.Sequential(
            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
        )
        self.img_fc = nn.Sequential(nn.Flatten(), nn.Linear(128 * 14 * 14, 256))
        self.classifier = nn.Sequential(nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.3), nn.Linear(256, num_classes))

    def forward(self, x_img, x_hog):
        hog = self.hog_fc(x_hog)
        img = self.img_fc(self.img_cnn(x_img))
        return self.classifier(torch.cat([hog, img], dim=1))


# üöÄ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è

def train():
    transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])
    dataset = FullHOGDataset(IMG_DIR, HOG_DIR, transform)
    hog_input_size = dataset[0][1].shape[0]

    val_size = int(len(dataset) * VALIDATION_SPLIT)
    train_size = len(dataset) - val_size
    train_ds, val_ds = random_split(dataset, [train_size, val_size])

    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("üñ•Ô∏è –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø—Ä–∏—Å—Ç—Ä—ñ–π:", device)

    model = DualChannelNet(num_classes=len(CLASS_NAMES), hog_input_size=hog_input_size).to(device)

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞, –¥–µ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –º–æ–¥–µ–ª—å
    for name, param in model.named_parameters():
        print(f"{name} ‚Üí {param.device}")
        break  # –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –æ–¥–Ω–æ–≥–æ —à–∞—Ä—É

    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()

    best_val_acc = 0
    total_start = time.time()

    for epoch in range(NUM_EPOCHS):
        print(f"\nüîÅ Epoch {epoch + 1}/{NUM_EPOCHS}")
        model.train()
        total_loss, correct, total = 0, 0, 0
        start_time = time.time()

        loop = tqdm(train_loader, desc="Train")
        for i, (images, hogs, labels) in enumerate(loop):
            images, hogs, labels = images.to(device), hogs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images, hogs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            correct += (outputs.argmax(1) == labels).sum().item()
            total += labels.size(0)

            loop.set_postfix(loss=total_loss / (i + 1), acc=100 * correct / total)

        train_acc = 100 * correct / total
        print(f"‚úÖ Train Loss: {total_loss:.2f}, Accuracy: {train_acc:.2f}%")

        # üîç –í–∞–ª—ñ–¥–∞—Ü—ñ—è
        model.eval()
        val_loss, val_correct, val_total = 0, 0, 0
        all_preds, all_labels = [], []
        with torch.no_grad():
            for images, hogs, labels in val_loader:
                images, hogs, labels = images.to(device), hogs.to(device), labels.to(device)
                outputs = model(images, hogs)
                val_loss += criterion(outputs, labels).item()
                preds = outputs.argmax(1)
                val_correct += (preds == labels).sum().item()
                val_total += labels.size(0)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

        val_acc = 100 * val_correct / val_total
        print(f"üìä Val Loss: {val_loss:.2f}, Accuracy: {val_acc:.2f}%")

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), MODEL_NAME)
            print(f"üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –Ω–∞–π–∫—Ä–∞—â—É –º–æ–¥–µ–ª—å (val acc: {val_acc:.2f}%)")
            # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–∑–∞–¥ —É GCS
            model_blob = bucket.blob(MODEL_NAME)
            model_blob.upload_from_filename(MODEL_NAME)
            print(f"‚òÅÔ∏è –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É GCS —è–∫ {MODEL_NAME}")

        # üìä –†–µ—Å—É—Ä—Å–∏
        print(f"üß† CPU: {psutil.cpu_percent()}% | RAM: {psutil.virtual_memory().used / 1e9:.2f} GB")
        gpus = GPUtil.getGPUs()
        if gpus:
            gpu = gpus[0]
            print(f"üß† GPU: {gpu.memoryUsed:.1f}MB / {gpu.memoryTotal:.1f}MB | Load: {gpu.load * 100:.1f}%")

        print(f"‚è±Ô∏è –¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –µ–ø–æ—Ö–∏: {(time.time() - start_time) / 60:.2f} —Ö–≤")

    print(f"‚è±Ô∏è –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è: {(time.time() - total_start) / 60:.2f} —Ö–≤")

    print("\nüìâ Classification Report:")
    print(classification_report(all_labels, all_preds, target_names=CLASS_NAMES))
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=False, xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES, cmap="Blues")
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()


# ‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫
train()
